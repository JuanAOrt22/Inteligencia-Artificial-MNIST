{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5MvfaYmnfke"
      },
      "source": [
        "# CNN\n",
        "\n",
        "Red Neuronal Convolucional para la materia Tecnologías Exponenciales - TIC\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYr3ptD1nklQ"
      },
      "source": [
        "### Librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las librerías respectivas que vamos a usar a lo largo del trabajo. Principalmente Numpy para los arrays, Pil para manipular las imagenes a la hora de evaluarlo junto con colab files. \n",
        "\n",
        "Todo lo de tenserflow y keras son capas con las librerías necesarias para el modelo y el entrenamiento."
      ],
      "metadata": {
        "id": "Zl_J0TZcClZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLJi7O0hCEn3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from IPython.display import HTML, display\n",
        "import tensorflow as tf \n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "# Cargamos el dataset de MNIST con información sobre numeros escritos a mano.\n",
        "\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt58rBeCoBqX"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlwVE47Lntcq"
      },
      "source": [
        "### Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvUJGV0Huj1F"
      },
      "source": [
        "#### Training Values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí retraemos los datos de la base de datos de Keras que extraimos en las librerías. Los convertimos a variables para poder evaluarlo. \n",
        "\n",
        "Las primeras dos variables son las imagenes, y el numero que significaría la imagen en cuestion. Las otras dos variables tienen el proposito de servir para poder verificar la precisión del modelo, pero no serán utilizadas.\n",
        "\n",
        "Luego reescalamos las imagenes para tener una dimensión de 4, necesaria para el modelo.\n",
        "\n",
        "1 conjunto de 60000 imagenes de 28 * 28 pixeles\n",
        "\n",
        "Luego lo convertimos a float y lo normalizamos para una mayor precision."
      ],
      "metadata": {
        "id": "HB8910i-Dor1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJe-z6WUCH98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5057df36-2d31-4708-f212-fd16494473c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Cargamos los datos.\n",
        "\n",
        "(EntrenImg, EntrenNombre), (Testeo, TesteoNombre) = mnist.load_data()\n",
        "\n",
        "# Cambiamos el tamaño de las imagenes. Ejemplo: 60000 imagenes de 28 * 28.\n",
        "\n",
        "EntrenImg = EntrenImg.reshape(60000, 28, 28, 1)\n",
        "\n",
        "\n",
        "# Cambiamos los valores de la imagen a punto flotante.\n",
        "\n",
        "EntrenImg = EntrenImg.astype('float32')\n",
        "\n",
        "# Normalizamos la imagen.\n",
        "\n",
        "EntrenImg = EntrenImg / 255\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creando el modelo."
      ],
      "metadata": {
        "id": "g45456dOwObw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ypev2KSrFRLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aca optimizamos y creamos el modelo de entrenamiento.\n",
        "\n",
        "La secuencia con la que será evaluada el modelo que inciaremos tomando por un convolucional bidimensional, que ira obteniendo pequeños fragmentos de la imagen. En este caso el tamaño de las imagenes es de (3, 3), y con 28 fragmentos para los filtros.\n",
        "\n",
        "Luego con el MaxPooling hacemos un resumen de la información que tenemos. Finalmente con el Flatten achicamos esa información a algo unidimensional.\n",
        "\n",
        "Creamos luego varias capas con un dropout para el entrenamiento, hasta llegar a 10 neuronas, que van a hacer nuestras neuronas de salida."
      ],
      "metadata": {
        "id": "nNPviyXEEnXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential() # Iniciamos la sequencia.\n",
        "\n",
        "\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape = (28, 28, 1)))\n",
        "\n",
        "# Iniciamos una capa convolucional bidimensional. 28 filtros de 3, 3.\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "\n",
        "# Achicamos a una de 2 , 2\n",
        "\n",
        "model.add(Flatten()) \n",
        "\n",
        "# Achicamos el valor\n",
        "\n",
        "model.add(Dense(128, activation=tf.nn.relu, use_bias=True)) \n",
        "\n",
        "# Creamos una capa de 128 neuronas.\n",
        "\n",
        "model.add(Dropout(0.5)) \n",
        "\n",
        "# Bias de 0.5\n",
        "\n",
        "model.add(Dense(70, activation=tf.nn.relu, use_bias=True))\n",
        "\n",
        "# Creamos una capa de 70 neuronas.\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#  Bias\n",
        "\n",
        "model.add(Dense(10,activation=tf.nn.softmax)) \n",
        "\n",
        "# Ultimas 10 neuronas restantes."
      ],
      "metadata": {
        "id": "n70myB-8wMt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "3POr_tSFv6HG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el entrenador de Keras para entrenar nuestra red neuronal.\n",
        "\n",
        "La compilamos y luego empezamos con el entrenamiento en base a nuestra base de datos de imagenes. Repetimos 12 veces para asegurarnos una mayor precisión."
      ],
      "metadata": {
        "id": "296eW_eQQc3Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE6UM40eE8kR",
        "outputId": "a93bc27d-e35c-411f-fb38-5b9f05b483d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.5000 - accuracy: 0.8508\n",
            "Epoch 2/12\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2271 - accuracy: 0.9367\n",
            "Epoch 3/12\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1783 - accuracy: 0.9513\n",
            "Epoch 4/12\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1502 - accuracy: 0.9586\n",
            "Epoch 5/12\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1359 - accuracy: 0.9626\n",
            "Epoch 6/12\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1215 - accuracy: 0.9663\n",
            "Epoch 7/12\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1113 - accuracy: 0.9683\n",
            "Epoch 8/12\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1089 - accuracy: 0.9693\n",
            "Epoch 9/12\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1017 - accuracy: 0.9706\n",
            "Epoch 10/12\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0957 - accuracy: 0.9730\n",
            "Epoch 11/12\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0936 - accuracy: 0.9736\n",
            "Epoch 12/12\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0841 - accuracy: 0.9756\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4226b7d10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Pasamos los datos de lo que queremos entrenar.\n",
        "\n",
        "model.fit(x= EntrenImg,y= EntrenNombre, epochs=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando la IA"
      ],
      "metadata": {
        "id": "Sd9i6g9TwBTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente aquí subimos una imagen de 28*28.\n",
        "\n",
        "La abrimos con un Image.open(f\"nombredelarchivo\") y realizamos la predicción.\n",
        "\n",
        "La predicción nos devuelve un array con la posición de cada neurona, y esa posición la convertimos a html para resaltarla."
      ],
      "metadata": {
        "id": "m4p7zvW9FizN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos el archivo.\n",
        "\n",
        "files.upload()\n",
        "\n",
        "#Importamos la imagen con el nombre del archivo.\n",
        "\n",
        "x = Image.open(f\"1.png\")\n",
        "\n",
        "display(x)\n",
        "\n",
        "x = np.array(x)\n",
        "\n",
        "x = x.reshape(1, 28, 28, 1)\n",
        "\n",
        "# Realizamos la predicción.\n",
        "\n",
        "rta = model.predict(\n",
        "    x,\n",
        "    batch_size=None,\n",
        "    verbose=\"auto\",\n",
        "    steps=None,\n",
        "    callbacks=None,\n",
        "    max_queue_size= x.shape,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False,\n",
        ")\n",
        "\n",
        "# Escribimos que numero es.\n",
        "\n",
        "large = lambda x : display(HTML('<p style=\"font-size: 50px; color: #66D148\">'+str(x)+'</p>'))\n",
        "\n",
        "large(np.argmax(rta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "5xuQ-yRHXFUz",
        "outputId": "fde3d21a-5e39-4144-e4e8-b6d34a011d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5dfd6fad-fee7-4481-9cf9-99e8e4463328\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5dfd6fad-fee7-4481-9cf9-99e8e4463328\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "E5MvfaYmnfke",
        "WYr3ptD1nklQ",
        "xvUJGV0Huj1F",
        "g45456dOwObw"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}